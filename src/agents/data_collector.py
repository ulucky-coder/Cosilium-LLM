"""
LLM-top: Data Collection Agent
–ê–≥–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∫–æ–≥–¥–∞ RAG #3 –ø—É—Å—Ç
"""

from typing import Optional
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

from src.config import get_settings


class DataSource(BaseModel):
    """–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö"""
    tool: str  # gemini, claude, chatgpt, perplexity, tavily, notebooklm
    query: str  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    purpose: str  # –ó–∞—á–µ–º –Ω—É–∂–Ω—ã —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ
    priority: int  # 1-5, –≥–¥–µ 1 ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ
    expected_output: str  # –ß—Ç–æ –æ–∂–∏–¥–∞–µ–º –ø–æ–ª—É—á–∏—Ç—å


class DataCollectionPlan(BaseModel):
    """–ü–ª–∞–Ω —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
    task_summary: str
    missing_data: list[str]
    sources: list[DataSource]
    research_questions: list[str]
    document_structure: str  # –®–∞–±–ª–æ–Ω –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    estimated_completeness: float  # 0-1, –Ω–∞—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–Ω—ã–º –±—É–¥–µ—Ç –∞–Ω–∞–ª–∏–∑


DATA_COLLECTION_SYSTEM_PROMPT = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º –∏ —Å–±–æ—Ä—É –¥–∞–Ω–Ω—ã—Ö. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–ª–∞–Ω —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

## –î–û–°–¢–£–ü–ù–´–ï –ò–ù–°–¢–†–£–ú–ï–ù–¢–´

### –î–ª—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–∞–∫—Ç–æ–≤:
1. **Perplexity / Tavily** ‚Äî –ø–æ–∏—Å–∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
   - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, —Ç—Ä–µ–Ω–¥—ã, –Ω–æ–≤–æ—Å—Ç–∏
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
   - –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑

2. **Gemini 2.0 Flash** ‚Äî –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä—ë–º–æ–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
   - –ê–Ω–∞–ª–∏–∑ –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   - –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
   - –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–≥—Ä–∞—Ñ–∏–∫–∏)

### –î–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:
3. **Claude AI** ‚Äî –≥–ª—É–±–æ–∫–∏–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
   - –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
   - –í—ã—è–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
   - –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

4. **ChatGPT** ‚Äî –ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è
   - –°–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
   - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ–∑

### –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏:
5. **NotebookLM** ‚Äî –∞–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   - PDF –æ—Ç—á—ë—Ç—ã, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
   - –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
   - –ù–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏

## –ü–†–ò–ù–¶–ò–ü–´ –°–ë–û–†–ê –î–ê–ù–ù–´–•

1. **–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è** ‚Äî —Å–Ω–∞—á–∞–ª–∞ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –ø–æ—Ç–æ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ
2. **–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è** ‚Äî –∫–∞–∂–¥—ã–π —Ñ–∞–∫—Ç –ø—Ä–æ–≤–µ—Ä—è—Ç—å –º–∏–Ω–∏–º—É–º –≤ 2 –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
3. **–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å** ‚Äî –ø—Ä–æ–≤–µ—Ä—è—Ç—å –¥–∞—Ç—É –¥–∞–Ω–Ω—ã—Ö (–æ—Å–æ–±–µ–Ω–Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
4. **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî –¥–∞–Ω–Ω—ã–µ —Å—Ä–∞–∑—É –æ—Ä–≥–∞–Ω–∏–∑–æ–≤—ã–≤–∞—Ç—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

## –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê

```json
{
  "task_summary": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏",
  "missing_data": [
    "–ö–∞—Ç–µ–≥–æ—Ä–∏—è 1: —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç",
    "–ö–∞—Ç–µ–≥–æ—Ä–∏—è 2: ..."
  ],
  "sources": [
    {
      "tool": "perplexity",
      "query": "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å",
      "purpose": "–ó–∞—á–µ–º –Ω—É–∂–Ω—ã —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ",
      "priority": 1,
      "expected_output": "–ß—Ç–æ –æ–∂–∏–¥–∞–µ–º –ø–æ–ª—É—á–∏—Ç—å"
    }
  ],
  "research_questions": [
    "–í–æ–ø—Ä–æ—Å 1, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å",
    "–í–æ–ø—Ä–æ—Å 2..."
  ],
  "document_structure": "Markdown —à–∞–±–ª–æ–Ω –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è RAG #3",
  "estimated_completeness": 0.85
}
```
"""

DATA_COLLECTION_USER_PROMPT = """## –ó–∞–¥–∞—á–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{task}

## –¢–∏–ø –∑–∞–¥–∞—á–∏:
{task_type}

## –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

## –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:
{data_status}

---

–°–æ–∑–¥–∞–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:
1. –û–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö —É–∫–∞–∂–∏ –ª—É—á—à–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å
3. –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–π –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
4. –°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ —Å–∏—Å—Ç–µ–º—É
"""


class DataCollectionAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(self):
        settings = get_settings()

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
        if settings.llm_proxy_enabled:
            self.llm = ChatOpenAI(
                model="gpt-4o",
                temperature=0.3,
                max_tokens=4096,
                api_key=settings.llm_proxy_api_key,
                base_url=settings.llm_proxy_base_url,
            )
        else:
            self.llm = ChatOpenAI(
                model="gpt-4o",
                temperature=0.3,
                max_tokens=4096,
                api_key=settings.openai_api_key,
            )

    async def create_collection_plan(
        self,
        task: str,
        task_type: str,
        context: Optional[str] = None,
        existing_data: Optional[list[str]] = None
    ) -> DataCollectionPlan:
        """
        –°–æ–∑–¥–∞—Ç—å –ø–ª–∞–Ω —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–¥–∞—á–∏.

        Args:
            task: –û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
            task_type: –¢–∏–ø –∑–∞–¥–∞—á–∏ (strategy, research, investment, etc.)
            context: –ò–º–µ—é—â–∏–π—Å—è –∫–æ–Ω—Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å)
            existing_data: –°–ø–∏—Å–æ–∫ —É–∂–µ –∏–º–µ—é—â–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö

        Returns:
            DataCollectionPlan —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ø–ª–∞–Ω–æ–º
        """
        data_status = "–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç"
        if existing_data:
            data_status = f"–ò–º–µ—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ:\n" + "\n".join(f"- {d}" for d in existing_data)
        elif context:
            data_status = f"–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {context[:500]}..."

        messages = [
            SystemMessage(content=DATA_COLLECTION_SYSTEM_PROMPT),
            HumanMessage(content=DATA_COLLECTION_USER_PROMPT.format(
                task=task,
                task_type=task_type,
                context=context or "–ù–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω",
                data_status=data_status,
            ))
        ]

        response = await self.llm.ainvoke(messages)

        # –ü–∞—Ä—Å–∏–Ω–≥ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
        import json
        import re

        content = response.content

        # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ markdown –±–ª–æ–∫–∞ –µ—Å–ª–∏ –µ—Å—Ç—å
        json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        if json_match:
            content = json_match.group(1)

        try:
            data = json.loads(content)

            sources = [
                DataSource(**s) for s in data.get("sources", [])
            ]

            return DataCollectionPlan(
                task_summary=data.get("task_summary", task),
                missing_data=data.get("missing_data", []),
                sources=sources,
                research_questions=data.get("research_questions", []),
                document_structure=data.get("document_structure", ""),
                estimated_completeness=data.get("estimated_completeness", 0.5),
            )
        except json.JSONDecodeError:
            # Fallback ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω
            return self._create_fallback_plan(task, task_type)

    def _create_fallback_plan(self, task: str, task_type: str) -> DataCollectionPlan:
        """–ë–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω –µ—Å–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è"""

        base_sources = [
            DataSource(
                tool="perplexity",
                query=f"{task} —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ 2024-2025",
                purpose="–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
                priority=1,
                expected_output="–¶–∏—Ñ—Ä—ã, —Ç—Ä–µ–Ω–¥—ã, —Ñ–∞–∫—Ç—ã"
            ),
            DataSource(
                tool="tavily",
                query=f"{task} market research",
                purpose="–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏",
                priority=2,
                expected_output="–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"
            ),
            DataSource(
                tool="claude",
                query=f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {task}",
                purpose="–ì–ª—É–±–æ–∫–∏–π –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑",
                priority=2,
                expected_output="–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–Ω–∞–ª–∏–∑–∞, –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã"
            ),
            DataSource(
                tool="gemini",
                query=f"–°–æ–±–µ—Ä–∏ –≤—Å–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–µ–º–µ: {task}",
                purpose="–®–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                priority=3,
                expected_output="–û–±–∑–æ—Ä –¥–æ—Å—Ç—É–ø–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
            ),
        ]

        return DataCollectionPlan(
            task_summary=task,
            missing_data=["–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "–¢—Ä–µ–Ω–¥—ã —Ä—ã–Ω–∫–∞", "–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑", "–≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–µ –º–Ω–µ–Ω–∏—è"],
            sources=base_sources,
            research_questions=[
                f"–ö–∞–∫–æ–≤ —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞/—Å–µ–≥–º–µ–Ω—Ç–∞ –¥–ª—è {task}?",
                f"–ö–∞–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –≤–ª–∏—è—é—Ç –Ω–∞ {task}?",
                f"–ö—Ç–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–≥—Ä–æ–∫–∏ –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã?",
                f"–ö–∞–∫–∏–µ —Ä–∏—Å–∫–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç?",
            ],
            document_structure=self._get_default_document_structure(task_type),
            estimated_completeness=0.6,
        )

    def _get_default_document_structure(self, task_type: str) -> str:
        """–®–∞–±–ª–æ–Ω –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏"""

        templates = {
            "strategy": """# –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑: {–Ω–∞–∑–≤–∞–Ω–∏–µ}

## 1. –†–µ–∑—é–º–µ
- –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã (3-5 –ø—É–Ω–∫—Ç–æ–≤)

## 2. –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
### 2.1 –†–∞–∑–º–µ—Ä —Ä—ã–Ω–∫–∞
- TAM/SAM/SOM
- –î–∏–Ω–∞–º–∏–∫–∞ (CAGR)
- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö

### 2.2 –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–π –ª–∞–Ω–¥—à–∞—Ñ—Ç
| –ö–æ–º–ø–∞–Ω–∏—è | –î–æ–ª—è —Ä—ã–Ω–∫–∞ | –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã | –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã |
|----------|------------|-----------------|----------------|

### 2.3 –¢—Ä–µ–Ω–¥—ã
- –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ
- –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–µ
- –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ

## 3. SWOT-–∞–Ω–∞–ª–∏–∑
| Strengths | Weaknesses |
|-----------|------------|
| Opportunities | Threats |

## 4. –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
- Unit economics
- –ü—Ä–æ–≥–Ω–æ–∑ P&L
- –¢–æ—á–∫–∞ –±–µ–∑—É–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏

## 5. –†–∏—Å–∫–∏ –∏ –º–∏—Ç–∏–≥–∞—Ü–∏—è
| –†–∏—Å–∫ | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å | –í–ª–∏—è–Ω–∏–µ | –ú–∏—Ç–∏–≥–∞—Ü–∏—è |
|------|-------------|---------|-----------|

## 6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
1. ...
2. ...

## –ò—Å—Ç–æ—á–Ω–∏–∫–∏
- [–ò—Å—Ç–æ—á–Ω–∏–∫ 1](url) ‚Äî –¥–∞—Ç–∞ –¥–æ—Å—Ç—É–ø–∞
- ...
""",
            "research": """# –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: {–Ω–∞–∑–≤–∞–Ω–∏–µ}

## 1. –í–≤–µ–¥–µ–Ω–∏–µ
- –¶–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

## 2. –û–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã
### –ö–ª—é—á–µ–≤—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
1. ...

### –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–Ω–∞–Ω–∏–π
...

## 3. –î–∞–Ω–Ω—ã–µ
### 3.1 –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ | –ò—Å—Ç–æ—á–Ω–∏–∫ | –î–∞—Ç–∞ |
|---------|----------|----------|------|

### 3.2 –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
...

## 4. –ê–Ω–∞–ª–∏–∑
### 4.1 –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Ö–æ–¥–∫–∏
...

### 4.2 –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏
...

## 5. –í—ã–≤–æ–¥—ã
...

## 6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
...

## –ë–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—è
...
""",
            "investment": """# –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {–Ω–∞–∑–≤–∞–Ω–∏–µ}

## 1. Executive Summary
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: BUY/HOLD/SELL
- Target price / –û—Ü–µ–Ω–∫–∞
- –ö–ª—é—á–µ–≤—ã–µ –¥—Ä–∞–π–≤–µ—Ä—ã

## 2. –ë–∏–∑–Ω–µ—Å-–º–æ–¥–µ–ª—å
- –ü—Ä–æ–¥—É–∫—Ç/—É—Å–ª—É–≥–∞
- –ú–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏—è
- Unit economics

## 3. –†—ã–Ω–æ–∫
- TAM/SAM/SOM
- –ö–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è
- –ë–∞—Ä—å–µ—Ä—ã –≤—Ö–æ–¥–∞

## 4. –§–∏–Ω–∞–Ω—Å—ã
### –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
| –ì–æ–¥ | Revenue | EBITDA | Net Income |
|-----|---------|--------|------------|

### –ü—Ä–æ–≥–Ω–æ–∑
...

## 5. –û—Ü–µ–Ω–∫–∞
### DCF
- WACC: X%
- Terminal growth: Y%
- Fair value: $Z

### –ú—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–æ—Ä—ã
| –ú–µ—Ç—Ä–∏–∫–∞ | –ö–æ–º–ø–∞–Ω–∏—è | Peers | Premium/Discount |
|---------|----------|-------|------------------|

## 6. –†–∏—Å–∫–∏
| –†–∏—Å–∫ | Probability | Impact | Risk-adjusted |
|------|-------------|--------|---------------|

## 7. –ö–∞—Ç–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
- –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ
- –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ

## –ò—Å—Ç–æ—á–Ω–∏–∫–∏
...
""",
        }

        return templates.get(task_type, templates["research"])

    def format_plan_as_markdown(self, plan: DataCollectionPlan) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω –∫–∞–∫ Markdown –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""

        md = f"""# –ü–ª–∞–Ω —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

## –ó–∞–¥–∞—á–∞
{plan.task_summary}

## –ù–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
"""
        for item in plan.missing_data:
            md += f"- {item}\n"

        md += "\n## –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –∑–∞–ø—Ä–æ—Å—ã\n\n"

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        by_priority = {}
        for source in plan.sources:
            if source.priority not in by_priority:
                by_priority[source.priority] = []
            by_priority[source.priority].append(source)

        priority_labels = {1: "üî¥ –ö—Ä–∏—Ç–∏—á–Ω–æ", 2: "üü° –í–∞–∂–Ω–æ", 3: "üü¢ –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ", 4: "‚ö™ –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ", 5: "‚ö™ –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ"}

        for priority in sorted(by_priority.keys()):
            md += f"### {priority_labels.get(priority, f'–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç {priority}')}\n\n"
            for source in by_priority[priority]:
                md += f"""**{source.tool.upper()}**
- –ó–∞–ø—Ä–æ—Å: `{source.query}`
- –¶–µ–ª—å: {source.purpose}
- –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {source.expected_output}

"""

        md += "## –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã\n"
        for i, q in enumerate(plan.research_questions, 1):
            md += f"{i}. {q}\n"

        md += f"\n## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n\n```markdown\n{plan.document_structure}\n```\n"

        md += f"\n---\n**–û–∂–∏–¥–∞–µ–º–∞—è –ø–æ–ª–Ω–æ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞:** {plan.estimated_completeness*100:.0f}%\n"

        return md
